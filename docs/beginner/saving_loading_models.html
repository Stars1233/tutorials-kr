
<!DOCTYPE html>


<html lang="ko" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta property="article:modified_time" content="2022-11-30T07:09:41+00:00" /><meta property="og:title" content="모델 저장하기 & 불러오기" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://tutorials.pytorch.kr/beginner/saving_loading_models.html" />
<meta property="og:site_name" content="PyTorch Tutorials KR" />
<meta property="og:description" content="Author: Matthew Inkawhich, 번역: 박정환, 김제필,. 이 문서에서는 PyTorch 모델을 저장하고 불러오는 다양한 방법을 제공합니다. 이 문서 전체를 다 읽는 것도 좋은 방법이지만, 필요한 사용 예의 코드만 참고하는 것도 고려해보세요. 모델을 저장하거나 불러올 때는 3가지의 핵심 함수와 익숙해질 필요가 있습니다: torch.save: 직렬화된 객체를 디스크에 저장합니다. 이 함수는 Python의 pickle 을 사용하여 직렬화합니다. 이 함수를 사용하여 모든 종류의 객체의 모델, Tensor 및 사전을 저..." />
<meta property="og:image" content="https://tutorials.pytorch.kr/_static/logos/logo-kr-sm-dark.png" />
<meta property="og:image:alt" content="PyTorch Tutorials KR" />
<meta name="description" content="Author: Matthew Inkawhich, 번역: 박정환, 김제필,. 이 문서에서는 PyTorch 모델을 저장하고 불러오는 다양한 방법을 제공합니다. 이 문서 전체를 다 읽는 것도 좋은 방법이지만, 필요한 사용 예의 코드만 참고하는 것도 고려해보세요. 모델을 저장하거나 불러올 때는 3가지의 핵심 함수와 익숙해질 필요가 있습니다: torch.save: 직렬화된 객체를 디스크에 저장합니다. 이 함수는 Python의 pickle 을 사용하여 직렬화합니다. 이 함수를 사용하여 모든 종류의 객체의 모델, Tensor 및 사전을 저..." />
<meta property="og:ignore_canonical" content="true" />

    <title>모델 저장하기 &amp; 불러오기 &#8212; 파이토치 한국어 튜토리얼 (PyTorch tutorials in Korean)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=536c50fe" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=4d2595e5" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/pytorch_theme.css?v=c326296f" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=097efa9c" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom2.css?v=b169ea90" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=725a5b95"></script>
    <script src="../_static/doctools.js?v=92e14aea"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/translations.js?v=b5f768d8"></script>
    <script src="../_static/katex.min.js?v=be8ff15f"></script>
    <script src="../_static/auto-render.min.js?v=ad136472"></script>
    <script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'beginner/saving_loading_models';</script>
    <link rel="canonical" href="https://tutorials.pytorch.kr/beginner/saving_loading_models.html" />
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="색인" href="../genindex.html" />
    <link rel="search" title="검색" href="../search.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2022년 11월 30일"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->

<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<script type="text/javascript" src="../_static/js/dropdown-menu.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Nanum+Gothic:wght@400;700&family=Nanum+Gothic+Coding:wght@400;700&family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="../_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="tutorials">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=G-LZRD6GXDLF" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'G-LZRD6GXDLF');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.8.0+cu128');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="ko"/>
    <meta name="docbuild:last-update" content="2022년 11월 30일"/>

  </head>

<body data-feedback-url="https://github.com/PyTorchKorea/tutorials-kr" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.kr/" aria-label="PyTorchKR"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="learnDropdownButton" data-toggle="learn-dropdown" class="learn-dropdown">
              <a class="with-down-arrow">
                <span>배우기</span>
              </a>
              <div class="learn-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.kr/get-started/locally/">
                  <span class="dropdown-title">PyTorch 시작하기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/beginner/basics/intro.html">
                  <span class="dropdown-title">기본 익히기</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/hub/">
                  <span class="dropdown-title">한국어 모델 허브</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <a href="https://pytorch.kr/blog/">
              <span>블로그</span>
            </a>
          </li>

          <li class="main-menu-item">
          <div id="docsDropdownButton" data-toggle="docs-dropdown" class="docs-dropdown">
              <a class="with-down-arrow">
              <span>문서</span>
              </a>
              <div class="docs-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/" target="_blank">
                  <span class="dropdown-title">PyTorch API</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/domains/">
                  <span class="dropdown-title">Domain API 소개</span>
                </a>
                <a class="nav-dropdown-item" href="https://tutorials.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 튜토리얼</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials/" target="_blank">
                  <span class="dropdown-title">Official Tutorials</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="communityDropdownButton" data-toggle="community-dropdown" class="community-dropdown">
              <a class="with-down-arrow">
              <span>커뮤니티</span>
              </a>
              <div class="community-dropdown-menu dropdown-menu">
                <a class="nav-dropdown-item" href="https://discuss.pytorch.kr/" target="_self">
                  <span class="dropdown-title">한국어 커뮤니티</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.kr/resources/">
                  <span class="dropdown-title">개발자 정보</span>
                </a>
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
              </div>
            </div>
          </li>

        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
          <i class="fa-solid fa-xmark"></i>
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>배우기</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.kr/get-started/locally/">PyTorch 시작하기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/beginner/basics/intro.html">기본 익히기</a>
           </li>
           <li>
             <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
           </li>
           <li>
             <a href="https://pytorch.kr/hub/">한국어 모델 허브</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
           </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a href="https://pytorch.kr/blog/">블로그</a>
         </li>
         <li class="resources-mobile-menu-title">
           <a>문서</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/" target="_blank">PyTorch API</a>
          </li>
          <li>
            <a href="https://pytorch.kr/domains/">Domain API 소개</a>
          </li>
          <li>
            <a href="https://tutorials.pytorch.kr/">한국어 튜토리얼</a>
          </li>
          <li>
            <a href="https://docs.pytorch.org/tutorials/" target="_blank">Official Tutorials</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>커뮤니티</a>
        </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://discuss.pytorch.kr/">한국어 커뮤니티</a>
          </li>
          <li>
            <a href="https://pytorch.kr/resources/">개발자 정보</a>
          </li>
          <li>
            <a href="https://landscape.pytorch.org/" target="_blank">Landscape</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../index.html" class="version">v2.8.0+cu128</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<div class="search-container-wrapper">
  <div id="sphinx-search" class="search-container">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </div>

  <div id="google-search" class="search-container" style="display:none;">
    <div class="gcse-search-wrapper">
      <i class="fa-solid fa-magnifying-glass" aria-hidden="true"></i>
      <div class="gcse-search"></div>
    </div>
  </div>

  <div class="search-toggle-container" data-bs-title="Google Search Off" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <div class="search-toggle-inner">
      <label class="switch">
        <input type="checkbox" id="search-toggle">
        <span class="slider round"></span>
      </label>
    </div>
  </div>
</div>

<script>
  document.addEventListener('DOMContentLoaded', function() {
  // Define the search callback
  const myWebSearchStartingCallback = (gname, query) => {
    if (typeof dataLayer !== 'undefined' && query) {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'google_search',
        'search_term': query,
        'event_category': 'Search',
        'event_label': 'Google Search'
      });
    }
    return '';
  };

  // Set up the GCSE search callbacks
  window.__gcse || (window.__gcse = {});
  window.__gcse.searchCallbacks = {
    web: { starting: myWebSearchStartingCallback }
  };

  if (window.location.pathname.includes('/search.html')) {
    document.body.classList.add('search-page');
  }

  // Function to reinitialize Google CSE
  function reinitializeGoogleSearch() {
    if (window.__gcse && window.__gcse.initializationCallback) {
      window.__gcse.initializationCallback();
    }
  }

  // Function to handle search toggle
  function handleSearchToggle(toggle, sphinxSearch, googleSearch) {
    if (!toggle || !sphinxSearch || !googleSearch) return;

    // Check if the URL contains /stable/ or /tutorials/
    const currentUrl = window.location.href;
    // TODO: We've had reports that the google programmable search is returning stale documentation,
    //       Simple reproduction is to turn google search on and search for multinomial which will
    //       result in returning 1.8.1 documentation.
    //       We should turn this back on when we resolve that bug.
    const shouldDefaultToGoogle = false;
    const savedPreference = localStorage.getItem('searchPreference');

    // Set initial state
    if (savedPreference === 'google' || (savedPreference === null && shouldDefaultToGoogle)) {
      toggle.checked = true;
      sphinxSearch.style.display = 'none';
      googleSearch.style.display = 'block';
      if (savedPreference === null) {
        localStorage.setItem('searchPreference', 'google');
      }
      reinitializeGoogleSearch();
    } else {
      toggle.checked = false;
      sphinxSearch.style.display = 'block';
      googleSearch.style.display = 'none';
    }

    // Update tooltip
    updateTooltip(toggle.checked);

    // Skip if already initialized
    if (toggle.hasAttribute('data-initialized')) return;
    toggle.setAttribute('data-initialized', 'true');

    toggle.addEventListener('change', function() {
      if (this.checked) {
        sphinxSearch.style.display = 'none';
        googleSearch.style.display = 'block';
        localStorage.setItem('searchPreference', 'google');
        reinitializeGoogleSearch();
        trackSearchEngineSwitch('Google');
      } else {
        sphinxSearch.style.display = 'block';
        googleSearch.style.display = 'none';
        localStorage.setItem('searchPreference', 'sphinx');
        trackSearchEngineSwitch('Sphinx');
      }

      updateTooltip(this.checked);
      updateMobileSearch();
    });
  }

  // Update tooltip based on toggle state
  function updateTooltip(isChecked) {
    const tooltipElement = document.querySelector('.search-toggle-container');
    if (!tooltipElement) return;

    tooltipElement.setAttribute('data-bs-title', isChecked ? 'Google Search On' : 'Google Search Off');

    if (bootstrap && bootstrap.Tooltip) {
      const tooltipInstance = bootstrap.Tooltip.getInstance(tooltipElement);
      if (tooltipInstance) tooltipInstance.dispose();
      new bootstrap.Tooltip(tooltipElement);
    }
  }

  // Track search engine switch
  function trackSearchEngineSwitch(engine) {
    if (typeof dataLayer !== 'undefined') {
      window.dataLayer = window.dataLayer || [];
      dataLayer.push({
        'event': 'search_engine_switch',
        'event_category': 'Search',
        'event_label': engine
      });
    }
  }

  // Function to update mobile search based on current toggle state
  function updateMobileSearch() {
    const toggle = document.getElementById('search-toggle');
    if (!toggle) return;

    const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
    if (!mobileSearchContainer) return;

    const mobileSphinxSearch = mobileSearchContainer.querySelector('#sphinx-search');
    const mobileGoogleSearch = mobileSearchContainer.querySelector('#google-search');

    if (mobileSphinxSearch && mobileGoogleSearch) {
      mobileSphinxSearch.style.display = toggle.checked ? 'none' : 'block';
      mobileGoogleSearch.style.display = toggle.checked ? 'block' : 'none';

      if (toggle.checked) {
        reinitializeGoogleSearch();
      }
    }
  }

  // Initialize desktop search toggle
  const toggle = document.getElementById('search-toggle');
  const sphinxSearch = document.getElementById('sphinx-search');
  const googleSearch = document.getElementById('google-search');
  handleSearchToggle(toggle, sphinxSearch, googleSearch);

  // Set placeholder text for Google search input
  const observer = new MutationObserver(function() {
    document.querySelectorAll('.gsc-input input').forEach(input => {
      if (input && !input.hasAttribute('data-placeholder-set')) {
        input.setAttribute('placeholder', 'Search the docs ...');
        input.setAttribute('data-placeholder-set', 'true');
      }
    });
  });

  observer.observe(document.body, { childList: true, subtree: true });

  // Fix for scroll jump issue - improved approach
  function setupSearchInputHandlers(input) {
    if (input.hasAttribute('data-scroll-fixed')) return;
    input.setAttribute('data-scroll-fixed', 'true');

    let lastScrollPosition = 0;
    let isTyping = false;
    let scrollTimeout;

    // Save position before typing starts
    input.addEventListener('keydown', () => {
      lastScrollPosition = window.scrollY;
      isTyping = true;

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);
    });

    // Only maintain scroll position during typing
    function maintainScroll() {
      if (document.activeElement === input && isTyping) {
        window.scrollTo(0, lastScrollPosition);
        requestAnimationFrame(maintainScroll);
      }
    }

    input.addEventListener('focus', () => {
      // Just store initial position but don't force it
      lastScrollPosition = window.scrollY;
    });

    input.addEventListener('input', () => {
      isTyping = true;
      window.scrollTo(0, lastScrollPosition);

      // Reset typing state after a short delay
      clearTimeout(scrollTimeout);
      scrollTimeout = setTimeout(() => {
        isTyping = false;
      }, 100);

      requestAnimationFrame(maintainScroll);
    });
  }

  // Apply to all search inputs and observe for new ones
  function applyToSearchInputs() {
    document.querySelectorAll('.search-container input, .gsc-input input').forEach(setupSearchInputHandlers);
  }

  applyToSearchInputs();

  const searchObserver = new MutationObserver(applyToSearchInputs);
  searchObserver.observe(document.body, { childList: true, subtree: true });

  // Watch for mobile menu creation
  const mobileMenuObserver = new MutationObserver(function(mutations) {
    for (const mutation of mutations) {
      if (!mutation.addedNodes.length) continue;

      // Style mobile search inputs
      document.querySelectorAll('.sidebar-header-items__end .navbar-item .search-container-wrapper .gsc-input input').forEach(input => {
        if (input) {
          input.setAttribute('placeholder', 'Search the docs ...');
          input.style.paddingLeft = '36px';
        }
      });

      // Check for mobile search container
      const mobileSearchContainer = document.querySelector('.sidebar-header-items__end .navbar-item .search-container-wrapper');
      if (!mobileSearchContainer) continue;

      const mobileToggle = mobileSearchContainer.querySelector('#search-toggle');
      if (mobileToggle && toggle) {
        // Sync mobile toggle with desktop toggle
        mobileToggle.checked = toggle.checked;
        updateMobileSearch();

        // Add event listener to mobile toggle if not already added
        if (!mobileToggle.hasAttribute('data-initialized')) {
          mobileToggle.setAttribute('data-initialized', 'true');
          mobileToggle.addEventListener('change', function() {
            // Sync desktop toggle with mobile toggle
            toggle.checked = this.checked;
            // Trigger change event on desktop toggle to update both
            toggle.dispatchEvent(new Event('change'));
          });
        }
      }
    }
  });

  mobileMenuObserver.observe(document.body, { childList: true, subtree: true });

  // Ensure Google CSE is properly loaded
  if (window.__gcse) {
    window.__gcse.callback = function() {
      // This will run after Google CSE is fully loaded
      if (toggle && toggle.checked) {
        reinitializeGoogleSearch();
      }
    };
  } else {
    window.__gcse = {
      callback: function() {
        if (toggle && toggle.checked) {
          reinitializeGoogleSearch();
        }
      }
    };
  }
});
</script>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/PyTorchKorea/tutorials-kr" title="한국어 튜토리얼 GitHub 저장소" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">한국어 튜토리얼 GitHub 저장소</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.pytorch.kr/" title="파이토치 한국어 커뮤니티" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">파이토치 한국어 커뮤니티</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page">모델 저장하기 &amp; 불러오기</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="모델 저장하기 &amp; 불러오기">
        <meta itemprop="position" content="1">
      </div>
    </div>

    
    <script>
      if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function () {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
    
    
    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">beginner/saving_loading_models</div>
      <a id="colab-link" data-behavior="call-to-action-event" data-response="Run in Google Colab" target="_blank">
        <div id="google-colab-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-colab.svg" />
          <div class="call-to-action-desktop-view">Run in Google Colab</div>
          <div class="call-to-action-mobile-view">Colab</div>
        </div>
      </a>
      <a id="notebook-link" data-behavior="call-to-action-event" data-response="Download Notebook">
        <div id="download-notebook-link">
          <img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg" />
          <div class="call-to-action-desktop-view">Download Notebook</div>
          <div class="call-to-action-mobile-view">Notebook</div>
        </div>
      </a>
      <a id="github-link" data-behavior="call-to-action-event" data-response="View on Github" target="_blank">
        <div id="github-view-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-github.svg" />
          <div class="call-to-action-desktop-view">View on GitHub</div>
          <div class="call-to-action-mobile-view">GitHub</div>
        </div>
      </a>
    </div>
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">참고</p>
<p><a class="reference internal" href="#sphx-glr-download-beginner-saving-loading-models-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="sphx-glr-beginner-saving-loading-models-py">
<span id="id1"></span><h1>모델 저장하기 &amp; 불러오기<a class="headerlink" href="#sphx-glr-beginner-saving-loading-models-py" title="Link to this heading">#</a></h1>
<dl class="simple">
<dt><strong>Author:</strong> <a class="reference external" href="https://github.com/MatthewInkawhich">Matthew Inkawhich</a></dt><dd><p><strong>번역</strong>: <a class="reference external" href="http://github.com/9bow">박정환</a>, <a class="reference external" href="http://github.com/garlicvread">김제필</a></p>
</dd>
</dl>
<p>이 문서에서는 PyTorch 모델을 저장하고 불러오는 다양한 방법을 제공합니다.
이 문서 전체를 다 읽는 것도 좋은 방법이지만, 필요한 사용 예의 코드만 참고하는
것도 고려해보세요.</p>
<p>모델을 저장하거나 불러올 때는 3가지의 핵심 함수와 익숙해질 필요가 있습니다:</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/torch.html?highlight=save#torch.save">torch.save</a>:
직렬화된 객체를 디스크에 저장합니다. 이 함수는 Python의
<a class="reference external" href="https://docs.python.org/3/library/pickle.html">pickle</a> 을 사용하여 직렬화합니다.
이 함수를 사용하여 모든 종류의 객체의 모델, Tensor 및 사전을 저장할 수 있습니다.</p></li>
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/torch.html?highlight=torch%20load#torch.load">torch.load</a>:
<a class="reference external" href="https://docs.python.org/3/library/pickle.html">pickle</a>을 사용하여
저장된 객체 파일들을 역직렬화하여 메모리에 올립니다. 이 함수는 데이터를 장치에 불러올
때에도 사용됩니다.
(<a class="reference external" href="#device">장치 간 모델 저장하기 &amp; 불러오기</a> 참고)</p></li>
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=load_state_dict#torch.nn.Module.load_state_dict">torch.nn.Module.load_state_dict</a>:
역직렬화된 <em>state_dict</em> 를 사용하여 모델의 매개변수들을 불러옵니다.
<em>state_dict</em> 에 대한 더 자세한 정보는 <a class="reference external" href="#state-dict">state_dict가 무엇인가요?</a> 를 참고하세요.</p></li>
</ol>
<p><strong>목차:</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="#state-dict">state_dict가 무엇인가요?</a></p></li>
<li><p><a class="reference external" href="#inference">추론(inference)를 위해 모델 저장하기 &amp; 불러오기</a></p></li>
<li><p><a class="reference external" href="#checkpoint">일반 체크포인트(checkpoint) 저장하기 &amp; 불러오기</a></p></li>
<li><p><a class="reference external" href="#multiple">여러 개(multiple)의 모델을 하나의 파일에 저장하기</a></p></li>
<li><p><a class="reference external" href="#warmstart">다른 모델의 매개변수를 사용하여 빠르게 모델 시작하기(warmstart)</a></p></li>
<li><p><a class="reference external" href="#device">장치(device)간 모델 저장하기 &amp; 불러오기</a></p></li>
</ul>
<section id="state-dict">
<h2><code class="docutils literal notranslate"><span class="pre">state_dict</span></code> 가 무엇인가요?<a class="headerlink" href="#state-dict" title="Link to this heading">#</a></h2>
<p>PyTorch에서 <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> 모델의 학습 가능한 매개변수(예. 가중치와 편향)들은
모델의 매개변수에 포함되어 있습니다(model.parameters()로 접근합니다).
<em>state_dict</em> 는 간단히 말해 각 계층을 매개변수 텐서로 매핑되는 Python 사전(dict)
객체입니다. 이 때, 학습 가능한 매개변수를 갖는 계층(합성곱 계층, 선형 계층 등)
및 등록된 버퍼들(batchnorm의 running_mean)만이 모델의 <em>state_dict</em> 에 항목을
가짐을 유의하시기 바랍니다. 옵티마이저 객체(<code class="docutils literal notranslate"><span class="pre">torch.optim</span></code>) 또한 옵티마이저의
상태 뿐만 아니라 사용된 하이퍼 매개변수(Hyperparameter) 정보가 포함된
<em>state_dict</em> 를 갖습니다.</p>
<p><em>state_dict</em> 객체는 Python 사전이기 때문에 쉽게 저장하거나 갱신하거나 바꾸거나
되살릴 수 있으며, PyTorch 모델과 옵티마이저에 엄청난 모듈성(modularity)을 제공합니다.</p>
<section id="id4">
<h3>예제:<a class="headerlink" href="#id4" title="Link to this heading">#</a></h3>
<p><a class="reference internal" href="blitz/cifar10_tutorial.html"><span class="doc">분류기(Classifier) 학습하기</span></a> 튜토리얼에서 사용한 간단한 모델의
<em>state_dict</em> 를 살펴보도록 하겠습니다.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 모델 정의</span>
<span class="k">class</span><span class="w"> </span><span class="nc">TheModelClass</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TheModelClass</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># 모델 초기화</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">()</span>

<span class="c1"># 옵티마이저 초기화</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># 모델의 state_dict 출력</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model&#39;s state_dict:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param_tensor</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param_tensor</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="n">param_tensor</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="c1"># 옵티마이저의 state_dict 출력</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimizer&#39;s state_dict:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">var_name</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">var_name</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="n">var_name</span><span class="p">])</span>
</pre></div>
</div>
<p><strong>출력:</strong></p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>Model<span class="s1">&#39;s state_dict:</span>
<span class="s1">conv1.weight     torch.Size([6, 3, 5, 5])</span>
<span class="s1">conv1.bias   torch.Size([6])</span>
<span class="s1">conv2.weight     torch.Size([16, 6, 5, 5])</span>
<span class="s1">conv2.bias   torch.Size([16])</span>
<span class="s1">fc1.weight   torch.Size([120, 400])</span>
<span class="s1">fc1.bias     torch.Size([120])</span>
<span class="s1">fc2.weight   torch.Size([84, 120])</span>
<span class="s1">fc2.bias     torch.Size([84])</span>
<span class="s1">fc3.weight   torch.Size([10, 84])</span>
<span class="s1">fc3.bias     torch.Size([10])</span>

<span class="s1">Optimizer&#39;</span>s<span class="w"> </span>state_dict:
state<span class="w">    </span><span class="o">{}</span>
param_groups<span class="w">     </span><span class="o">[{</span><span class="s1">&#39;lr&#39;</span>:<span class="w"> </span><span class="m">0</span>.001,<span class="w"> </span><span class="s1">&#39;momentum&#39;</span>:<span class="w"> </span><span class="m">0</span>.9,<span class="w"> </span><span class="s1">&#39;dampening&#39;</span>:<span class="w"> </span><span class="m">0</span>,<span class="w"> </span><span class="s1">&#39;weight_decay&#39;</span>:<span class="w"> </span><span class="m">0</span>,<span class="w"> </span><span class="s1">&#39;nesterov&#39;</span>:<span class="w"> </span>False,<span class="w"> </span><span class="s1">&#39;params&#39;</span>:<span class="w"> </span><span class="o">[</span><span class="m">4675713712</span>,<span class="w"> </span><span class="m">4675713784</span>,<span class="w"> </span><span class="m">4675714000</span>,<span class="w"> </span><span class="m">4675714072</span>,<span class="w"> </span><span class="m">4675714216</span>,<span class="w"> </span><span class="m">4675714288</span>,<span class="w"> </span><span class="m">4675714432</span>,<span class="w"> </span><span class="m">4675714504</span>,<span class="w"> </span><span class="m">4675714648</span>,<span class="w"> </span><span class="m">4675714720</span><span class="o">]}]</span>
</pre></div>
</div>
</section>
</section>
<section id="inference">
<h2>추론(inference)를 위해 모델 저장하기 &amp; 불러오기<a class="headerlink" href="#inference" title="Link to this heading">#</a></h2>
<section id="id5">
<h3><code class="docutils literal notranslate"><span class="pre">state_dict</span></code> 저장하기 / 불러오기 (권장)<a class="headerlink" href="#id5" title="Link to this heading">#</a></h3>
<p><strong>저장하기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>불러오기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>PyTorch 버전 1.6에서는 <code class="docutils literal notranslate"><span class="pre">torch.save</span></code> 가 새로운 Zip파일-기반의 파일
포맷을 사용하도록 변경되었습니다. <code class="docutils literal notranslate"><span class="pre">torch.load</span></code> 는 예전 방식의 파일들을
읽어올 수 있도록 하고 있습니다. 어떤 이유에서든 <code class="docutils literal notranslate"><span class="pre">torch.save</span></code> 가 예전
방식을 사용하도록 하고 싶다면, <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> 매개변수로
<code class="docutils literal notranslate"><span class="pre">_use_new_zipfile_serialization=False</span></code> 을 전달하세요.</p>
</div>
<p>추론을 위해 모델을 저장할 때는 그 모델의 학습된 매개변수만 저장하면 됩니다.
<code class="docutils literal notranslate"><span class="pre">torch.save()</span></code> 를 사용하여 모델의 <em>state_dict</em> 를 저장하는 것이 나중에 모델을
사용할 때 가장 유연하게 사용할 수 있는, 모델 저장 시 권장하는 방법입니다.</p>
<p>PyTorch에서는 모델을 저장할 때 <code class="docutils literal notranslate"><span class="pre">.pt</span></code> 또는 <code class="docutils literal notranslate"><span class="pre">.pth</span></code> 확장자를 사용하는 것이
일반적인 규칙입니다.</p>
<p>추론을 실행하기 전에 반드시 <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code> 을 호출하여 드롭아웃 및 배치
정규화를 평가 모드로 설정하여야 합니다. 이 과정을 거치지 않으면 일관성 없는
추론 결과가 출력됩니다.</p>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p><code class="docutils literal notranslate"><span class="pre">load_state_dict()</span></code> 함수에는 저장된 객체의 경로가 아닌, 사전 객체를
전달해야 하는 것에 유의하세요. 따라서 저장된 <em>state_dict</em> 를 <code class="docutils literal notranslate"><span class="pre">load_state_dict()</span></code>
함수에 전달하기 전에 반드시 역직렬화를 해야 합니다. 예를 들어,
<code class="docutils literal notranslate"><span class="pre">model.load_state_dict(PATH)</span></code> 과 같은 식으로 사용하면 안됩니다.</p>
</div>
<div class="admonition note">
<p class="admonition-title">참고</p>
<p>만약 (검증 손실(validation loss) 결과에 따라) 가장 성능이 좋은 모델만 유지할
계획이라면, <code class="docutils literal notranslate"><span class="pre">best_model_state</span> <span class="pre">=</span> <span class="pre">model.state_dict()</span></code> 은 모델의 복사본이 아닌
모델의 현재 상태에 대한 참조(reference)만 반환한다는 사실을 잊으시면 안됩니다!
따라서 <code class="docutils literal notranslate"><span class="pre">best_model_state</span></code> 을 직렬화(serialize)하거나,
<code class="docutils literal notranslate"><span class="pre">best_model_state</span> <span class="pre">=</span> <span class="pre">deepcopy(model.state_dict())</span></code> 을 사용해야 합니다.
그렇지 않으면, 제일 좋은 성능을 내는 <code class="docutils literal notranslate"><span class="pre">best_model_state</span></code> 은 계속되는 학습 단계에서
갱신될 것입니다. 결과적으로, 최종 모델의 상태는 과적합(overfit)된 상태가 됩니다.</p>
</div>
</section>
<section id="id6">
<h3>전체 모델 저장하기/불러오기<a class="headerlink" href="#id6" title="Link to this heading">#</a></h3>
<p><strong>저장하기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>불러오기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 모델 클래스는 어딘가에 반드시 선언되어 있어야 합니다.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
<p>이 저장하기/불러오기 과정은 가장 직관적인 문법을 사용하며 적은 양의
코드를 사용합니다. 이러한 방식으로 모델을 저장하는 것은 Python의
<a class="reference external" href="https://docs.python.org/3/library/pickle.html">pickle</a> 모듈을 사용하여
전체 모듈을 저장하게 됩니다. 하지만 pickle은 모델 그 자체를 저장하지 않기 때문에
직렬화된 데이터가 모델을 저장할 때 사용한 특정 클래스 및 디렉토리 경로(구조)에
얽매인다는 것이 이 방식의 단점입니다. 대신에 클래스가 위치한 파일의 경로를
저장해두고, 불러오는 시점에 사용합니다. 이러한 이유 때문에, 만들어둔 코드를
다른 프로젝트에서 사용하거나 리팩토링 후에 다양한 이유로 동작하지 않을 수
있습니다.</p>
<p>PyTorch에서는 모델을 저장할 때 <code class="docutils literal notranslate"><span class="pre">.pt</span></code> 또는 <code class="docutils literal notranslate"><span class="pre">.pth</span></code> 확장자를 사용하는 것이
일반적인 규칙입니다.</p>
<p>추론을 실행하기 전에는 반드시 <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code> 을 호출하여 드롭아웃 및 배치
정규화를 평가 모드로 설정하여야 합니다. 이것을 하지 않으면 추론 결과가 일관성
없게 출력됩니다.</p>
<section id="exportedprogram">
<h4>ExportedProgram 저장하기<a class="headerlink" href="#exportedprogram" title="Link to this heading">#</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">torch.export``를</span> <span class="pre">사용하고</span> <span class="pre">있다면,</span> <span class="pre">``torch.export.save()</span></code> 와 <code class="docutils literal notranslate"><span class="pre">torch.export.load()</span></code> API를 사용하여
<code class="docutils literal notranslate"><span class="pre">.pt2</span></code> 확장자를 갖는 <code class="docutils literal notranslate"><span class="pre">ExportedProgram</span></code> 을 저장하고 불러올 수 있습니다:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SimpleModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
     <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
         <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">10</span>

<span class="c1"># 예시 입력 생성</span>
<span class="n">sample_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># 모델 내보내기</span>
<span class="n">exported_program</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">SimpleModel</span><span class="p">(),</span> <span class="n">sample_input</span><span class="p">)</span>

<span class="c1"># ExportedProgram 저장하기</span>
<span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">exported_program</span><span class="p">,</span> <span class="s1">&#39;exported_program.pt2&#39;</span><span class="p">)</span>

<span class="c1"># ExportedProgram 불러오기</span>
<span class="n">saved_exported_program</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;exported_program.pt2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="checkpoint">
<h2>추론 / 학습 재개를 위해 일반 체크포인트(checkpoint) 저장하기 &amp; 불러오기<a class="headerlink" href="#checkpoint" title="Link to this heading">#</a></h2>
<section id="id7">
<h3>저장하기:<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
            <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="s1">&#39;model_state_dict&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
            <span class="o">...</span>
            <span class="p">},</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id8">
<h3>불러오기:<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">TheOptimizerClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">])</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">])</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="c1"># - or -</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<p>추론 또는 학습 재개를 위해 일반 체크포인트를 저장할 때는 반드시 모델의
<em>state_dict</em> 보다 많은 것들을 저장해야 합니다. 모델이 학습을 하며 갱신되는
버퍼와 매개변수가 포함된 옵티마이저의 <em>state_dict</em> 도 함께 저장하는 것이
중요합니다. 그 외에도 마지막 에폭(epoch), 최근에 기록된 학습 손실, 외부
<code class="docutils literal notranslate"><span class="pre">torch.nn.Embedding</span></code> 계층 등도 함께 저장합니다. 결과적으로, 이런 체크포인트는
종종 모델만 저장하는 것보다 2~3배 정도 커지게 됩니다.</p>
<p>여러가지를 함께 저장하려면, 사전(dictionary) 자료형으로 만든 후
<code class="docutils literal notranslate"><span class="pre">torch.save()</span></code> 를 사용하여 직렬화합니다. PyTorch가 이러한 체크포인트를 저장할
때는 <code class="docutils literal notranslate"><span class="pre">.tar</span></code> 확장자를 사용하는 것이 일반적인 규칙입니다.</p>
<p>항목들을 불러올 때에는 먼저 모델과 옵티마이저를 초기화한 후, <code class="docutils literal notranslate"><span class="pre">torch.load()</span></code>
를 사용하여 사전을 불러옵니다. 이후로는 저장된 항목들을 사전에 원하는대로 사전에
질의하여 쉽게 접근할 수 있습니다.</p>
<p>추론을 실행하기 전에는 반드시 <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code> 을 호출하여 드롭아웃 및 배치
정규화를 평가 모드로 설정하여야 합니다. 이것을 하지 않으면 추론 결과가 일관성
없게 출력됩니다. 만약 학습을 계속하고 싶다면, <code class="docutils literal notranslate"><span class="pre">model.train()</span></code> 을 호출하여
학습 모드로 전환되도록 해야 합니다.</p>
</section>
</section>
<section id="multiple">
<h2>여러개(multiple)의 모델을 하나의 파일에 저장하기<a class="headerlink" href="#multiple" title="Link to this heading">#</a></h2>
<section id="id9">
<h3>저장하기:<a class="headerlink" href="#id9" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
            <span class="s1">&#39;modelA_state_dict&#39;</span><span class="p">:</span> <span class="n">modelA</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;modelB_state_dict&#39;</span><span class="p">:</span> <span class="n">modelB</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;optimizerA_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizerA</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">&#39;optimizerB_state_dict&#39;</span><span class="p">:</span> <span class="n">optimizerB</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="o">...</span>
            <span class="p">},</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id10">
<h3>불러오기:<a class="headerlink" href="#id10" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">modelA</span> <span class="o">=</span> <span class="n">TheModelAClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">modelB</span> <span class="o">=</span> <span class="n">TheModelBClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">optimizerA</span> <span class="o">=</span> <span class="n">TheOptimizerAClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">optimizerB</span> <span class="o">=</span> <span class="n">TheOptimizerBClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">modelA</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;modelA_state_dict&#39;</span><span class="p">])</span>
<span class="n">modelB</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;modelB_state_dict&#39;</span><span class="p">])</span>
<span class="n">optimizerA</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizerA_state_dict&#39;</span><span class="p">])</span>
<span class="n">optimizerB</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizerB_state_dict&#39;</span><span class="p">])</span>

<span class="n">modelA</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">modelB</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="c1"># - or -</span>
<span class="n">modelA</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">modelB</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<p>GAN, Seq2Seq 또는 앙상블 모델과 같이 여러개의 여러개의 <code class="docutils literal notranslate"><span class="pre">torch.nn.Modules</span></code> 로
구성된 모델을 저장하는 경우에는 일반 체크포인트를 저장할 때와 같은 방식을
따릅니다. 즉, 각 모델의 <em>state_dict</em> 와 해당 옵티마이저를 사전으로 저장합니다.
앞에서 언급했던 것과 같이, 학습을 재개하는데 필요한 다른 항목들을 사전에 추가하여
저장할 수 있습니다.</p>
<p>PyTorch가 이러한 체크포인트를 저장할 때는 <code class="docutils literal notranslate"><span class="pre">.tar</span></code> 확장자를 사용하는 것이
일반적인 규칙입니다.</p>
<p>항목들을 불러올 때에는 먼저 모델과 옵티마이저를 초기화한 후, <code class="docutils literal notranslate"><span class="pre">torch.load()</span></code>
를 사용하여 사전을 불러옵니다. 이후로는 저장된 항목들을 사전에 원하는대로 사전에
질의하여 쉽게 접근할 수 있습니다.</p>
<p>추론을 실행하기 전에는 반드시 <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code> 을 호출하여 드롭아웃 및 배치
정규화를 평가 모드로 설정하여야 합니다. 이것을 하지 않으면 추론 결과가 일관성
없게 출력됩니다. 만약 학습을 계속하고 싶다면, <code class="docutils literal notranslate"><span class="pre">model.train()</span></code> 을 호출하여
학습 모드로 설정해야 합니다.</p>
</section>
</section>
<section id="warmstart">
<h2>다른 모델의 매개변수를 사용하여 빠르게 모델 시작하기(warmstart)<a class="headerlink" href="#warmstart" title="Link to this heading">#</a></h2>
<section id="id11">
<h3>저장하기:<a class="headerlink" href="#id11" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">modelA</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id12">
<h3>불러오기:<a class="headerlink" href="#id12" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">modelB</span> <span class="o">=</span> <span class="n">TheModelBClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">modelB</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>부분적으로 모델을 불러오거나, 모델의 일부를 불러오는 것은 전이학습 또는
새로운 복잡한 모델을 학습할 때 일반적인 시나리오입니다. 학습된 매개변수를
사용하면, 일부만 사용한다 하더라도 학습 과정을 빠르게 시작할 수 있고,
처음부터 시작하는 것보다 훨씬 빠르게 모델이 수렴하도록 도울 것입니다.</p>
<p>몇몇 키를 제외하고 <em>state_dict</em> 의 일부를 불러오거나, 적재하려는 모델보다
더 많은 키를 갖고 있는 <em>state_dict</em> 를 불러올 때에는 <code class="docutils literal notranslate"><span class="pre">load_state_dict()</span></code>
함수에서 <code class="docutils literal notranslate"><span class="pre">strict</span></code> 인자를 <strong>False</strong> 로 설정하여 일치하지 않는 키들을
무시하도록 해야 합니다.</p>
<p>한 계층에서 다른 계층으로 매개변수를 불러오고 싶지만, 일부 키가 일치하지
않을 때에는 적재하려는 모델의 키와 일치하도록 <em>state_dict</em> 의 매개변수 키의
이름을 변경하면 됩니다.</p>
</section>
</section>
<section id="device">
<h2>장치(device)간 모델 저장하기 &amp; 불러오기<a class="headerlink" href="#device" title="Link to this heading">#</a></h2>
<section id="gpu-cpu">
<h3>GPU에서 저장하고 CPU에서 불러오기<a class="headerlink" href="#gpu-cpu" title="Link to this heading">#</a></h3>
<p><strong>저장하기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>불러오기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<p>GPU에서 학습한 모델을 CPU에서 불러올 때는 <code class="docutils literal notranslate"><span class="pre">torch.load()</span></code> 함수의
<code class="docutils literal notranslate"><span class="pre">map_location</span></code> 인자에 <code class="docutils literal notranslate"><span class="pre">torch.device('cpu')</span></code> 을 전달합니다.
이 경우에는 Tensor에 저장된 내용들은 <code class="docutils literal notranslate"><span class="pre">map_location</span></code> 인자를 사용하여 CPU 장치에
동적으로 재배치됩니다.</p>
</section>
<section id="gpu-gpu">
<h3>GPU에서 저장하고 GPU에서 불러오기<a class="headerlink" href="#gpu-gpu" title="Link to this heading">#</a></h3>
<p><strong>저장하기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>불러오기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="c1"># 모델에서 사용하는 input Tensor들은 input = input.to(device) 을 호출해야 합니다.</span>
</pre></div>
</div>
<p>GPU에서 학습한 모델을 GPU에서 불러올 때에는, 초기화된 <code class="docutils literal notranslate"><span class="pre">model</span></code> 에
<code class="docutils literal notranslate"><span class="pre">model.to(torch.device('cuda'))</span></code> 을 호출하여 CUDA 최적화된 모델로 변환해야
합니다. 또한, 모델에 데이터를 제공하는 모든 입력에 <code class="docutils literal notranslate"><span class="pre">.to(torch.device('cuda'))</span></code>
함수를 호출해야 합니다. <code class="docutils literal notranslate"><span class="pre">my_tensor.to(device)</span></code> 를 호출하면 GPU에 <code class="docutils literal notranslate"><span class="pre">my_tensor</span></code>
의 복사본을 반환하기 때문에, Tensor를 직접 덮어써야 합니다:
<code class="docutils literal notranslate"><span class="pre">my_tensor</span> <span class="pre">=</span> <span class="pre">my_tensor.to(torch.device('cuda'))</span></code> .</p>
</section>
<section id="cpu-gpu">
<h3>CPU에서 저장하고 GPU에서 불러오기<a class="headerlink" href="#cpu-gpu" title="Link to this heading">#</a></h3>
<p><strong>저장하기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>불러오기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">))</span>  <span class="c1"># 사용할 GPU 장치 번호를 선택합니다.</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="c1"># 모델에서 사용하는 input Tensor들은 input = input.to(device) 을 호출해야 합니다.</span>
</pre></div>
</div>
<p>CPU에서 학습한 모델을 GPU에서 불러올 때는 <code class="docutils literal notranslate"><span class="pre">torch.load()</span></code> 함수의
<code class="docutils literal notranslate"><span class="pre">map_location</span></code> 인자에 <code class="docutils literal notranslate"><span class="pre">cuda:device_id</span></code> 을 설정합니다. 이렇게 하면 모델이 해당
GPU 장치에 불러와집니다. 다음으로 <code class="docutils literal notranslate"><span class="pre">model.to(torch.device('cuda'))</span></code> 을 호출하여
모델의 매개변수 Tensor들을 CUDA Tensor들로 변환해야 합니다. 마지막으로 모든
모델 입력에 <code class="docutils literal notranslate"><span class="pre">.to(torch.device('cuda'))</span></code> 을 사용하여 CUDA 최적화된 모델을 위한
데이터로 만들어야 합니다. <code class="docutils literal notranslate"><span class="pre">my_tensor.to(device)</span></code> 를 호출하면 GPU에 <code class="docutils literal notranslate"><span class="pre">my_tensor</span></code>
의 복사본을 반환합니다. 이 동작은 <code class="docutils literal notranslate"><span class="pre">my_tensor</span></code> 를 덮어쓰지 않기 때문에, Tensor를
직접 덮어써야 합니다: <code class="docutils literal notranslate"><span class="pre">my_tensor</span> <span class="pre">=</span> <span class="pre">my_tensor.to(torch.device('cuda'))</span></code> .</p>
</section>
<section id="torch-nn-dataparallel">
<h3><code class="docutils literal notranslate"><span class="pre">torch.nn.DataParallel</span></code> 모델 저장하기<a class="headerlink" href="#torch-nn-dataparallel" title="Link to this heading">#</a></h3>
<p><strong>저장하기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>불러오기:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 사용할 장치에 불러옵니다.</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">torch.nn.DataParallel</span></code> 은 병렬 GPU 활용을 가능하게 하는 모델 래퍼(wrapper)입니다.
<code class="docutils literal notranslate"><span class="pre">DataParallel</span></code> 모델을 범용적으로 저장하려면 <code class="docutils literal notranslate"><span class="pre">model.module.state_dict()</span></code> 을
사용하면 됩니다. 이렇게 하면 원하는 모든 장치에 원하는 방식으로 유연하게 모델을
불러올 수 있습니다.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 0.000 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-beginner-saving-loading-models-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/e139fbbcadcc4d83aab8995db4b9147c/saving_loading_models.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">saving_loading_models.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/7d5771891cc8e2f733352e4fc8fc63b6/saving_loading_models.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">saving_loading_models.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/43a7730c9a544e14d3674f172c611879/saving_loading_models.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">saving_loading_models.zip</span></code></a></p>
</div>
</div>
</section>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
</div>

<div class="footer-info">
  <p class="copyright">
    
      
        © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      
      <br/>
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#state-dict"><code class="docutils literal notranslate"><span class="pre">state_dict</span></code> 가 무엇인가요?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">예제:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference">추론(inference)를 위해 모델 저장하기 &amp; 불러오기</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5"><code class="docutils literal notranslate"><span class="pre">state_dict</span></code> 저장하기 / 불러오기 (권장)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">전체 모델 저장하기/불러오기</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#exportedprogram">ExportedProgram 저장하기</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#checkpoint">추론 / 학습 재개를 위해 일반 체크포인트(checkpoint) 저장하기 &amp; 불러오기</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">저장하기:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">불러오기:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple">여러개(multiple)의 모델을 하나의 파일에 저장하기</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">저장하기:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">불러오기:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#warmstart">다른 모델의 매개변수를 사용하여 빠르게 모델 시작하기(warmstart)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">저장하기:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">불러오기:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#device">장치(device)간 모델 저장하기 &amp; 불러오기</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpu-cpu">GPU에서 저장하고 CPU에서 불러오기</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpu-gpu">GPU에서 저장하고 GPU에서 불러오기</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cpu-gpu">CPU에서 저장하고 GPU에서 불러오기</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#torch-nn-dataparallel"><code class="docutils literal notranslate"><span class="pre">torch.nn.DataParallel</span></code> 모델 저장하기</a></li>
</ul>
</li>
</ul>
  </nav></div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>PyTorchKorea @ GitHub</h2>
        <p>파이토치 한국 사용자 모임을 GitHub에서 만나보세요.</p>
        <a class="with-right-arrow" href="https://github.com/PyTorchKorea">GitHub로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 튜토리얼</h2>
        <p>한국어로 번역 중인 파이토치 튜토리얼을 만나보세요.</p>
        <a class="with-right-arrow" href="https://tutorials.pytorch.kr/">튜토리얼로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 커뮤니티</h2>
        <p>다른 사용자들과 의견을 나누고, 도와주세요!</p>
        <a class="with-right-arrow" href="https://discuss.pytorch.kr/">커뮤니티로 이동</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.kr/" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="https://pytorch.kr/">파이토치 한국 사용자 모임</a></li>
          <li><a href="https://pytorch.kr/about">사용자 모임 소개</a></li>
          <li><a href="https://pytorch.kr/contributors">기여해주신 분들</a></li>
          <li><a href="https://pytorch.kr/resources/">리소스</a></li>
          <li><a href="https://pytorch.kr/coc">행동 강령</a></li>
        </ul>
      </div>
    </div>

    <div class="trademark-disclaimer">
      <ul>
        <li>이 사이트는 독립적인 파이토치 사용자 커뮤니티로, 최신 버전이 아니거나 잘못된 내용이 포함되어 있을 수 있습니다. This site is an independent user community and may be out of date or contain incorrect information.</li>
        <li><a href="https://pytorch.kr/coc">행동 강령</a>을 읽고 지켜주세요. PyTorch 공식 로고 사용 규정은 <a href="https://www.linuxfoundation.org/policies/">Linux Foundation의 정책</a>을 따릅니다. Please read and follow <a href="https://pytorch.kr/coc">our code of conduct</a>. All PyTorch trademark policy applicable to <a href="https://www.linuxfoundation.org/policies/">Linux Foundation's policies</a>.</li>
      </ul>
    </div>
  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2018-2025, PyTorch &amp; 파이토치 한국 사용자 모임(PyTorchKR).
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6 버전으로 생성되었습니다.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "\ubaa8\ub378 \uc800\uc7a5\ud558\uae30 \u0026 \ubd88\ub7ec\uc624\uae30",
       "headline": "\ubaa8\ub378 \uc800\uc7a5\ud558\uae30 \u0026 \ubd88\ub7ec\uc624\uae30",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/beginner/saving_loading_models.html",
       "articleBody": "\ucc38\uace0 Go to the end to download the full example code. \ubaa8\ub378 \uc800\uc7a5\ud558\uae30 \u0026 \ubd88\ub7ec\uc624\uae30# Author: Matthew Inkawhich\ubc88\uc5ed: \ubc15\uc815\ud658, \uae40\uc81c\ud544 \uc774 \ubb38\uc11c\uc5d0\uc11c\ub294 PyTorch \ubaa8\ub378\uc744 \uc800\uc7a5\ud558\uace0 \ubd88\ub7ec\uc624\ub294 \ub2e4\uc591\ud55c \ubc29\ubc95\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc774 \ubb38\uc11c \uc804\uccb4\ub97c \ub2e4 \uc77d\ub294 \uac83\ub3c4 \uc88b\uc740 \ubc29\ubc95\uc774\uc9c0\ub9cc, \ud544\uc694\ud55c \uc0ac\uc6a9 \uc608\uc758 \ucf54\ub4dc\ub9cc \ucc38\uace0\ud558\ub294 \uac83\ub3c4 \uace0\ub824\ud574\ubcf4\uc138\uc694. \ubaa8\ub378\uc744 \uc800\uc7a5\ud558\uac70\ub098 \ubd88\ub7ec\uc62c \ub54c\ub294 3\uac00\uc9c0\uc758 \ud575\uc2ec \ud568\uc218\uc640 \uc775\uc219\ud574\uc9c8 \ud544\uc694\uac00 \uc788\uc2b5\ub2c8\ub2e4: torch.save: \uc9c1\ub82c\ud654\ub41c \uac1d\uccb4\ub97c \ub514\uc2a4\ud06c\uc5d0 \uc800\uc7a5\ud569\ub2c8\ub2e4. \uc774 \ud568\uc218\ub294 Python\uc758 pickle \uc744 \uc0ac\uc6a9\ud558\uc5ec \uc9c1\ub82c\ud654\ud569\ub2c8\ub2e4. \uc774 \ud568\uc218\ub97c \uc0ac\uc6a9\ud558\uc5ec \ubaa8\ub4e0 \uc885\ub958\uc758 \uac1d\uccb4\uc758 \ubaa8\ub378, Tensor \ubc0f \uc0ac\uc804\uc744 \uc800\uc7a5\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. torch.load: pickle\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc800\uc7a5\ub41c \uac1d\uccb4 \ud30c\uc77c\ub4e4\uc744 \uc5ed\uc9c1\ub82c\ud654\ud558\uc5ec \uba54\ubaa8\ub9ac\uc5d0 \uc62c\ub9bd\ub2c8\ub2e4. \uc774 \ud568\uc218\ub294 \ub370\uc774\ud130\ub97c \uc7a5\uce58\uc5d0 \ubd88\ub7ec\uc62c \ub54c\uc5d0\ub3c4 \uc0ac\uc6a9\ub429\ub2c8\ub2e4. (\uc7a5\uce58 \uac04 \ubaa8\ub378 \uc800\uc7a5\ud558\uae30 \u0026 \ubd88\ub7ec\uc624\uae30 \ucc38\uace0) torch.nn.Module.load_state_dict: \uc5ed\uc9c1\ub82c\ud654\ub41c state_dict \ub97c \uc0ac\uc6a9\ud558\uc5ec \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218\ub4e4\uc744 \ubd88\ub7ec\uc635\ub2c8\ub2e4. state_dict \uc5d0 \ub300\ud55c \ub354 \uc790\uc138\ud55c \uc815\ubcf4\ub294 state_dict\uac00 \ubb34\uc5c7\uc778\uac00\uc694? \ub97c \ucc38\uace0\ud558\uc138\uc694. \ubaa9\ucc28: state_dict\uac00 \ubb34\uc5c7\uc778\uac00\uc694? \ucd94\ub860(inference)\ub97c \uc704\ud574 \ubaa8\ub378 \uc800\uc7a5\ud558\uae30 \u0026 \ubd88\ub7ec\uc624\uae30 \uc77c\ubc18 \uccb4\ud06c\ud3ec\uc778\ud2b8(checkpoint) \uc800\uc7a5\ud558\uae30 \u0026 \ubd88\ub7ec\uc624\uae30 \uc5ec\ub7ec \uac1c(multiple)\uc758 \ubaa8\ub378\uc744 \ud558\ub098\uc758 \ud30c\uc77c\uc5d0 \uc800\uc7a5\ud558\uae30 \ub2e4\ub978 \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218\ub97c \uc0ac\uc6a9\ud558\uc5ec \ube60\ub974\uac8c \ubaa8\ub378 \uc2dc\uc791\ud558\uae30(warmstart) \uc7a5\uce58(device)\uac04 \ubaa8\ub378 \uc800\uc7a5\ud558\uae30 \u0026 \ubd88\ub7ec\uc624\uae30 state_dict \uac00 \ubb34\uc5c7\uc778\uac00\uc694?# PyTorch\uc5d0\uc11c torch.nn.Module \ubaa8\ub378\uc758 \ud559\uc2b5 \uac00\ub2a5\ud55c \ub9e4\uac1c\ubcc0\uc218(\uc608. \uac00\uc911\uce58\uc640 \ud3b8\ud5a5)\ub4e4\uc740 \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218\uc5d0 \ud3ec\ud568\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4(model.parameters()\ub85c \uc811\uadfc\ud569\ub2c8\ub2e4). state_dict \ub294 \uac04\ub2e8\ud788 \ub9d0\ud574 \uac01 \uacc4\uce35\uc744 \ub9e4\uac1c\ubcc0\uc218 \ud150\uc11c\ub85c \ub9e4\ud551\ub418\ub294 Python \uc0ac\uc804(dict) \uac1d\uccb4\uc785\ub2c8\ub2e4. \uc774 \ub54c, \ud559\uc2b5 \uac00\ub2a5\ud55c \ub9e4\uac1c\ubcc0\uc218\ub97c \uac16\ub294 \uacc4\uce35(\ud569\uc131\uacf1 \uacc4\uce35, \uc120\ud615 \uacc4\uce35 \ub4f1) \ubc0f \ub4f1\ub85d\ub41c \ubc84\ud37c\ub4e4(batchnorm\uc758 running_mean)\ub9cc\uc774 \ubaa8\ub378\uc758 state_dict \uc5d0 \ud56d\ubaa9\uc744 \uac00\uc9d0\uc744 \uc720\uc758\ud558\uc2dc\uae30 \ubc14\ub78d\ub2c8\ub2e4. \uc635\ud2f0\ub9c8\uc774\uc800 \uac1d\uccb4(torch.optim) \ub610\ud55c \uc635\ud2f0\ub9c8\uc774\uc800\uc758 \uc0c1\ud0dc \ubfd0\ub9cc \uc544\ub2c8\ub77c \uc0ac\uc6a9\ub41c \ud558\uc774\ud37c \ub9e4\uac1c\ubcc0\uc218(Hyperparameter) \uc815\ubcf4\uac00 \ud3ec\ud568\ub41c state_dict \ub97c \uac16\uc2b5\ub2c8\ub2e4. state_dict \uac1d\uccb4\ub294 Python \uc0ac\uc804\uc774\uae30 \ub54c\ubb38\uc5d0 \uc27d\uac8c \uc800\uc7a5\ud558\uac70\ub098 \uac31\uc2e0\ud558\uac70\ub098 \ubc14\uafb8\uac70\ub098 \ub418\uc0b4\ub9b4 \uc218 \uc788\uc73c\uba70, PyTorch \ubaa8\ub378\uacfc \uc635\ud2f0\ub9c8\uc774\uc800\uc5d0 \uc5c4\uccad\ub09c \ubaa8\ub4c8\uc131(modularity)\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4. \uc608\uc81c:# \ubd84\ub958\uae30(Classifier) \ud559\uc2b5\ud558\uae30 \ud29c\ud1a0\ub9ac\uc5bc\uc5d0\uc11c \uc0ac\uc6a9\ud55c \uac04\ub2e8\ud55c \ubaa8\ub378\uc758 state_dict \ub97c \uc0b4\ud3b4\ubcf4\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4. # \ubaa8\ub378 \uc815\uc758 class TheModelClass(nn.Module): def __init__(self): super(TheModelClass, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x # \ubaa8\ub378 \ucd08\uae30\ud654 model = TheModelClass() # \uc635\ud2f0\ub9c8\uc774\uc800 \ucd08\uae30\ud654 optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # \ubaa8\ub378\uc758 state_dict \ucd9c\ub825 print(\"Model\u0027s state_dict:\") for param_tensor in model.state_dict(): print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size()) # \uc635\ud2f0\ub9c8\uc774\uc800\uc758 state_dict \ucd9c\ub825 print(\"Optimizer\u0027s state_dict:\") for var_name in optimizer.state_dict(): print(var_name, \"\\t\", optimizer.state_dict()[var_name]) \ucd9c\ub825: Model\u0027s state_dict: conv1.weight torch.Size([6, 3, 5, 5]) conv1.bias torch.Size([6]) conv2.weight torch.Size([16, 6, 5, 5]) conv2.bias torch.Size([16]) fc1.weight torch.Size([120, 400]) fc1.bias torch.Size([120]) fc2.weight torch.Size([84, 120]) fc2.bias torch.Size([84]) fc3.weight torch.Size([10, 84]) fc3.bias torch.Size([10]) Optimizer\u0027s state_dict: state {} param_groups [{\u0027lr\u0027: 0.001, \u0027momentum\u0027: 0.9, \u0027dampening\u0027: 0, \u0027weight_decay\u0027: 0, \u0027nesterov\u0027: False, \u0027params\u0027: [4675713712, 4675713784, 4675714000, 4675714072, 4675714216, 4675714288, 4675714432, 4675714504, 4675714648, 4675714720]}] \ucd94\ub860(inference)\ub97c \uc704\ud574 \ubaa8\ub378 \uc800\uc7a5\ud558\uae30 \u0026 \ubd88\ub7ec\uc624\uae30# state_dict \uc800\uc7a5\ud558\uae30 / \ubd88\ub7ec\uc624\uae30 (\uad8c\uc7a5)# \uc800\uc7a5\ud558\uae30: torch.save(model.state_dict(), PATH) \ubd88\ub7ec\uc624\uae30: model = TheModelClass(*args, **kwargs) model.load_state_dict(torch.load(PATH, weights_only=True)) model.eval() \ucc38\uace0 PyTorch \ubc84\uc804 1.6\uc5d0\uc11c\ub294 torch.save \uac00 \uc0c8\ub85c\uc6b4 Zip\ud30c\uc77c-\uae30\ubc18\uc758 \ud30c\uc77c \ud3ec\ub9f7\uc744 \uc0ac\uc6a9\ud558\ub3c4\ub85d \ubcc0\uacbd\ub418\uc5c8\uc2b5\ub2c8\ub2e4. torch.load \ub294 \uc608\uc804 \ubc29\uc2dd\uc758 \ud30c\uc77c\ub4e4\uc744 \uc77d\uc5b4\uc62c \uc218 \uc788\ub3c4\ub85d \ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. \uc5b4\ub5a4 \uc774\uc720\uc5d0\uc11c\ub4e0 torch.save \uac00 \uc608\uc804 \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud558\ub3c4\ub85d \ud558\uace0 \uc2f6\ub2e4\uba74, kwargs \ub9e4\uac1c\ubcc0\uc218\ub85c _use_new_zipfile_serialization=False \uc744 \uc804\ub2ec\ud558\uc138\uc694. \ucd94\ub860\uc744 \uc704\ud574 \ubaa8\ub378\uc744 \uc800\uc7a5\ud560 \ub54c\ub294 \uadf8 \ubaa8\ub378\uc758 \ud559\uc2b5\ub41c \ub9e4\uac1c\ubcc0\uc218\ub9cc \uc800\uc7a5\ud558\uba74 \ub429\ub2c8\ub2e4. torch.save() \ub97c \uc0ac\uc6a9\ud558\uc5ec \ubaa8\ub378\uc758 state_dict \ub97c \uc800\uc7a5\ud558\ub294 \uac83\uc774 \ub098\uc911\uc5d0 \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud560 \ub54c \uac00\uc7a5 \uc720\uc5f0\ud558\uac8c \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294, \ubaa8\ub378 \uc800\uc7a5 \uc2dc \uad8c\uc7a5\ud558\ub294 \ubc29\ubc95\uc785\ub2c8\ub2e4. PyTorch\uc5d0\uc11c\ub294 \ubaa8\ub378\uc744 \uc800\uc7a5\ud560 \ub54c .pt \ub610\ub294 .pth \ud655\uc7a5\uc790\ub97c \uc0ac\uc6a9\ud558\ub294 \uac83\uc774 \uc77c\ubc18\uc801\uc778 \uaddc\uce59\uc785\ub2c8\ub2e4. \ucd94\ub860\uc744 \uc2e4\ud589\ud558\uae30 \uc804\uc5d0 \ubc18\ub4dc\uc2dc model.eval() \uc744 \ud638\ucd9c\ud558\uc5ec \ub4dc\ub86d\uc544\uc6c3 \ubc0f \ubc30\uce58 \uc815\uaddc\ud654\ub97c \ud3c9\uac00 \ubaa8\ub4dc\ub85c \uc124\uc815\ud558\uc5ec\uc57c \ud569\ub2c8\ub2e4. \uc774 \uacfc\uc815\uc744 \uac70\uce58\uc9c0 \uc54a\uc73c\uba74 \uc77c\uad00\uc131 \uc5c6\ub294 \ucd94\ub860 \uacb0\uacfc\uac00 \ucd9c\ub825\ub429\ub2c8\ub2e4. \ucc38\uace0 load_state_dict() \ud568\uc218\uc5d0\ub294 \uc800\uc7a5\ub41c \uac1d\uccb4\uc758 \uacbd\ub85c\uac00 \uc544\ub2cc, \uc0ac\uc804 \uac1d\uccb4\ub97c \uc804\ub2ec\ud574\uc57c \ud558\ub294 \uac83\uc5d0 \uc720\uc758\ud558\uc138\uc694. \ub530\ub77c\uc11c \uc800\uc7a5\ub41c state_dict \ub97c load_state_dict() \ud568\uc218\uc5d0 \uc804\ub2ec\ud558\uae30 \uc804\uc5d0 \ubc18\ub4dc\uc2dc \uc5ed\uc9c1\ub82c\ud654\ub97c \ud574\uc57c \ud569\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4, model.load_state_dict(PATH) \uacfc \uac19\uc740 \uc2dd\uc73c\ub85c \uc0ac\uc6a9\ud558\uba74 \uc548\ub429\ub2c8\ub2e4. \ucc38\uace0 \ub9cc\uc57d (\uac80\uc99d \uc190\uc2e4(validation loss) \uacb0\uacfc\uc5d0 \ub530\ub77c) \uac00\uc7a5 \uc131\ub2a5\uc774 \uc88b\uc740 \ubaa8\ub378\ub9cc \uc720\uc9c0\ud560 \uacc4\ud68d\uc774\ub77c\uba74, best_model_state = model.state_dict() \uc740 \ubaa8\ub378\uc758 \ubcf5\uc0ac\ubcf8\uc774 \uc544\ub2cc \ubaa8\ub378\uc758 \ud604\uc7ac \uc0c1\ud0dc\uc5d0 \ub300\ud55c \ucc38\uc870(reference)\ub9cc \ubc18\ud658\ud55c\ub2e4\ub294 \uc0ac\uc2e4\uc744 \uc78a\uc73c\uc2dc\uba74 \uc548\ub429\ub2c8\ub2e4! \ub530\ub77c\uc11c best_model_state \uc744 \uc9c1\ub82c\ud654(serialize)\ud558\uac70\ub098, best_model_state = deepcopy(model.state_dict()) \uc744 \uc0ac\uc6a9\ud574\uc57c \ud569\ub2c8\ub2e4. \uadf8\ub807\uc9c0 \uc54a\uc73c\uba74, \uc81c\uc77c \uc88b\uc740 \uc131\ub2a5\uc744 \ub0b4\ub294 best_model_state \uc740 \uacc4\uc18d\ub418\ub294 \ud559\uc2b5 \ub2e8\uacc4\uc5d0\uc11c \uac31\uc2e0\ub420 \uac83\uc785\ub2c8\ub2e4. \uacb0\uacfc\uc801\uc73c\ub85c, \ucd5c\uc885 \ubaa8\ub378\uc758 \uc0c1\ud0dc\ub294 \uacfc\uc801\ud569(overfit)\ub41c \uc0c1\ud0dc\uac00 \ub429\ub2c8\ub2e4. \uc804\uccb4 \ubaa8\ub378 \uc800\uc7a5\ud558\uae30/\ubd88\ub7ec\uc624\uae30# \uc800\uc7a5\ud558\uae30: torch.save(model, PATH) \ubd88\ub7ec\uc624\uae30: # \ubaa8\ub378 \ud074\ub798\uc2a4\ub294 \uc5b4\ub518\uac00\uc5d0 \ubc18\ub4dc\uc2dc \uc120\uc5b8\ub418\uc5b4 \uc788\uc5b4\uc57c \ud569\ub2c8\ub2e4. model = torch.load(PATH, weights_only=False) model.eval() \uc774 \uc800\uc7a5\ud558\uae30/\ubd88\ub7ec\uc624\uae30 \uacfc\uc815\uc740 \uac00\uc7a5 \uc9c1\uad00\uc801\uc778 \ubb38\ubc95\uc744 \uc0ac\uc6a9\ud558\uba70 \uc801\uc740 \uc591\uc758 \ucf54\ub4dc\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \ubc29\uc2dd\uc73c\ub85c \ubaa8\ub378\uc744 \uc800\uc7a5\ud558\ub294 \uac83\uc740 Python\uc758 pickle \ubaa8\ub4c8\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc804\uccb4 \ubaa8\ub4c8\uc744 \uc800\uc7a5\ud558\uac8c \ub429\ub2c8\ub2e4. \ud558\uc9c0\ub9cc pickle\uc740 \ubaa8\ub378 \uadf8 \uc790\uccb4\ub97c \uc800\uc7a5\ud558\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0 \uc9c1\ub82c\ud654\ub41c \ub370\uc774\ud130\uac00 \ubaa8\ub378\uc744 \uc800\uc7a5\ud560 \ub54c \uc0ac\uc6a9\ud55c \ud2b9\uc815 \ud074\ub798\uc2a4 \ubc0f \ub514\ub809\ud1a0\ub9ac \uacbd\ub85c(\uad6c\uc870)\uc5d0 \uc5bd\ub9e4\uc778\ub2e4\ub294 \uac83\uc774 \uc774 \ubc29\uc2dd\uc758 \ub2e8\uc810\uc785\ub2c8\ub2e4. \ub300\uc2e0\uc5d0 \ud074\ub798\uc2a4\uac00 \uc704\uce58\ud55c \ud30c\uc77c\uc758 \uacbd\ub85c\ub97c \uc800\uc7a5\ud574\ub450\uace0, \ubd88\ub7ec\uc624\ub294 \uc2dc\uc810\uc5d0 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc774\uc720 \ub54c\ubb38\uc5d0, \ub9cc\ub4e4\uc5b4\ub454 \ucf54\ub4dc\ub97c \ub2e4\ub978 \ud504\ub85c\uc81d\ud2b8\uc5d0\uc11c \uc0ac\uc6a9\ud558\uac70\ub098 \ub9ac\ud329\ud1a0\ub9c1 \ud6c4\uc5d0 \ub2e4\uc591\ud55c \uc774\uc720\ub85c \ub3d9\uc791\ud558\uc9c0 \uc54a\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4. PyTorch\uc5d0\uc11c\ub294 \ubaa8\ub378\uc744 \uc800\uc7a5\ud560 \ub54c .pt \ub610\ub294 .pth \ud655\uc7a5\uc790\ub97c \uc0ac\uc6a9\ud558\ub294 \uac83\uc774 \uc77c\ubc18\uc801\uc778 \uaddc\uce59\uc785\ub2c8\ub2e4. \ucd94\ub860\uc744 \uc2e4\ud589\ud558\uae30 \uc804\uc5d0\ub294 \ubc18\ub4dc\uc2dc model.eval() \uc744 \ud638\ucd9c\ud558\uc5ec \ub4dc\ub86d\uc544\uc6c3 \ubc0f \ubc30\uce58 \uc815\uaddc\ud654\ub97c \ud3c9\uac00 \ubaa8\ub4dc\ub85c \uc124\uc815\ud558\uc5ec\uc57c \ud569\ub2c8\ub2e4. \uc774\uac83\uc744 \ud558\uc9c0 \uc54a\uc73c\uba74 \ucd94\ub860 \uacb0\uacfc\uac00 \uc77c\uad00\uc131 \uc5c6\uac8c \ucd9c\ub825\ub429\ub2c8\ub2e4. ExportedProgram \uc800\uc7a5\ud558\uae30# torch.export``\ub97c \uc0ac\uc6a9\ud558\uace0 \uc788\ub2e4\uba74, ``torch.export.save() \uc640 torch.export.load() API\ub97c \uc0ac\uc6a9\ud558\uc5ec .pt2 \ud655\uc7a5\uc790\ub97c \uac16\ub294 ExportedProgram \uc744 \uc800\uc7a5\ud558\uace0 \ubd88\ub7ec\uc62c \uc218 \uc788\uc2b5\ub2c8\ub2e4: class SimpleModel(torch.nn.Module): def forward(self, x): return x + 10 # \uc608\uc2dc \uc785\ub825 \uc0dd\uc131 sample_input = torch.randn(5) # \ubaa8\ub378 \ub0b4\ubcf4\ub0b4\uae30 exported_program = torch.export.export(SimpleModel(), sample_input) # ExportedProgram \uc800\uc7a5\ud558\uae30 torch.export.save(exported_program, \u0027exported_program.pt2\u0027) # ExportedProgram \ubd88\ub7ec\uc624\uae30 saved_exported_program = torch.export.load(\u0027exported_program.pt2\u0027) \ucd94\ub860 / \ud559\uc2b5 \uc7ac\uac1c\ub97c \uc704\ud574 \uc77c\ubc18 \uccb4\ud06c\ud3ec\uc778\ud2b8(checkpoint) \uc800\uc7a5\ud558\uae30 \u0026 \ubd88\ub7ec\uc624\uae30# \uc800\uc7a5\ud558\uae30:# torch.save({ \u0027epoch\u0027: epoch, \u0027model_state_dict\u0027: model.state_dict(), \u0027optimizer_state_dict\u0027: optimizer.state_dict(), \u0027loss\u0027: loss, ... }, PATH) \ubd88\ub7ec\uc624\uae30:# model = TheModelClass(*args, **kwargs) optimizer = TheOptimizerClass(*args, **kwargs) checkpoint = torch.load(PATH, weights_only=True) model.load_state_dict(checkpoint[\u0027model_state_dict\u0027]) optimizer.load_state_dict(checkpoint[\u0027optimizer_state_dict\u0027]) epoch = checkpoint[\u0027epoch\u0027] loss = checkpoint[\u0027loss\u0027] model.eval() # - or - model.train() \ucd94\ub860 \ub610\ub294 \ud559\uc2b5 \uc7ac\uac1c\ub97c \uc704\ud574 \uc77c\ubc18 \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \uc800\uc7a5\ud560 \ub54c\ub294 \ubc18\ub4dc\uc2dc \ubaa8\ub378\uc758 state_dict \ubcf4\ub2e4 \ub9ce\uc740 \uac83\ub4e4\uc744 \uc800\uc7a5\ud574\uc57c \ud569\ub2c8\ub2e4. \ubaa8\ub378\uc774 \ud559\uc2b5\uc744 \ud558\uba70 \uac31\uc2e0\ub418\ub294 \ubc84\ud37c\uc640 \ub9e4\uac1c\ubcc0\uc218\uac00 \ud3ec\ud568\ub41c \uc635\ud2f0\ub9c8\uc774\uc800\uc758 state_dict \ub3c4 \ud568\uaed8 \uc800\uc7a5\ud558\ub294 \uac83\uc774 \uc911\uc694\ud569\ub2c8\ub2e4. \uadf8 \uc678\uc5d0\ub3c4 \ub9c8\uc9c0\ub9c9 \uc5d0\ud3ed(epoch), \ucd5c\uadfc\uc5d0 \uae30\ub85d\ub41c \ud559\uc2b5 \uc190\uc2e4, \uc678\ubd80 torch.nn.Embedding \uacc4\uce35 \ub4f1\ub3c4 \ud568\uaed8 \uc800\uc7a5\ud569\ub2c8\ub2e4. \uacb0\uacfc\uc801\uc73c\ub85c, \uc774\ub7f0 \uccb4\ud06c\ud3ec\uc778\ud2b8\ub294 \uc885\uc885 \ubaa8\ub378\ub9cc \uc800\uc7a5\ud558\ub294 \uac83\ubcf4\ub2e4 2~3\ubc30 \uc815\ub3c4 \ucee4\uc9c0\uac8c \ub429\ub2c8\ub2e4. \uc5ec\ub7ec\uac00\uc9c0\ub97c \ud568\uaed8 \uc800\uc7a5\ud558\ub824\uba74, \uc0ac\uc804(dictionary) \uc790\ub8cc\ud615\uc73c\ub85c \ub9cc\ub4e0 \ud6c4 torch.save() \ub97c \uc0ac\uc6a9\ud558\uc5ec \uc9c1\ub82c\ud654\ud569\ub2c8\ub2e4. PyTorch\uac00 \uc774\ub7ec\ud55c \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \uc800\uc7a5\ud560 \ub54c\ub294 .tar \ud655\uc7a5\uc790\ub97c \uc0ac\uc6a9\ud558\ub294 \uac83\uc774 \uc77c\ubc18\uc801\uc778 \uaddc\uce59\uc785\ub2c8\ub2e4. \ud56d\ubaa9\ub4e4\uc744 \ubd88\ub7ec\uc62c \ub54c\uc5d0\ub294 \uba3c\uc800 \ubaa8\ub378\uacfc \uc635\ud2f0\ub9c8\uc774\uc800\ub97c \ucd08\uae30\ud654\ud55c \ud6c4, torch.load() \ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0ac\uc804\uc744 \ubd88\ub7ec\uc635\ub2c8\ub2e4. \uc774\ud6c4\ub85c\ub294 \uc800\uc7a5\ub41c \ud56d\ubaa9\ub4e4\uc744 \uc0ac\uc804\uc5d0 \uc6d0\ud558\ub294\ub300\ub85c \uc0ac\uc804\uc5d0 \uc9c8\uc758\ud558\uc5ec \uc27d\uac8c \uc811\uadfc\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ucd94\ub860\uc744 \uc2e4\ud589\ud558\uae30 \uc804\uc5d0\ub294 \ubc18\ub4dc\uc2dc model.eval() \uc744 \ud638\ucd9c\ud558\uc5ec \ub4dc\ub86d\uc544\uc6c3 \ubc0f \ubc30\uce58 \uc815\uaddc\ud654\ub97c \ud3c9\uac00 \ubaa8\ub4dc\ub85c \uc124\uc815\ud558\uc5ec\uc57c \ud569\ub2c8\ub2e4. \uc774\uac83\uc744 \ud558\uc9c0 \uc54a\uc73c\uba74 \ucd94\ub860 \uacb0\uacfc\uac00 \uc77c\uad00\uc131 \uc5c6\uac8c \ucd9c\ub825\ub429\ub2c8\ub2e4. \ub9cc\uc57d \ud559\uc2b5\uc744 \uacc4\uc18d\ud558\uace0 \uc2f6\ub2e4\uba74, model.train() \uc744 \ud638\ucd9c\ud558\uc5ec \ud559\uc2b5 \ubaa8\ub4dc\ub85c \uc804\ud658\ub418\ub3c4\ub85d \ud574\uc57c \ud569\ub2c8\ub2e4. \uc5ec\ub7ec\uac1c(multiple)\uc758 \ubaa8\ub378\uc744 \ud558\ub098\uc758 \ud30c\uc77c\uc5d0 \uc800\uc7a5\ud558\uae30# \uc800\uc7a5\ud558\uae30:# torch.save({ \u0027modelA_state_dict\u0027: modelA.state_dict(), \u0027modelB_state_dict\u0027: modelB.state_dict(), \u0027optimizerA_state_dict\u0027: optimizerA.state_dict(), \u0027optimizerB_state_dict\u0027: optimizerB.state_dict(), ... }, PATH) \ubd88\ub7ec\uc624\uae30:# modelA = TheModelAClass(*args, **kwargs) modelB = TheModelBClass(*args, **kwargs) optimizerA = TheOptimizerAClass(*args, **kwargs) optimizerB = TheOptimizerBClass(*args, **kwargs) checkpoint = torch.load(PATH, weights_only=True) modelA.load_state_dict(checkpoint[\u0027modelA_state_dict\u0027]) modelB.load_state_dict(checkpoint[\u0027modelB_state_dict\u0027]) optimizerA.load_state_dict(checkpoint[\u0027optimizerA_state_dict\u0027]) optimizerB.load_state_dict(checkpoint[\u0027optimizerB_state_dict\u0027]) modelA.eval() modelB.eval() # - or - modelA.train() modelB.train() GAN, Seq2Seq \ub610\ub294 \uc559\uc0c1\ube14 \ubaa8\ub378\uacfc \uac19\uc774 \uc5ec\ub7ec\uac1c\uc758 \uc5ec\ub7ec\uac1c\uc758 torch.nn.Modules \ub85c \uad6c\uc131\ub41c \ubaa8\ub378\uc744 \uc800\uc7a5\ud558\ub294 \uacbd\uc6b0\uc5d0\ub294 \uc77c\ubc18 \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \uc800\uc7a5\ud560 \ub54c\uc640 \uac19\uc740 \ubc29\uc2dd\uc744 \ub530\ub985\ub2c8\ub2e4. \uc989, \uac01 \ubaa8\ub378\uc758 state_dict \uc640 \ud574\ub2f9 \uc635\ud2f0\ub9c8\uc774\uc800\ub97c \uc0ac\uc804\uc73c\ub85c \uc800\uc7a5\ud569\ub2c8\ub2e4. \uc55e\uc5d0\uc11c \uc5b8\uae09\ud588\ub358 \uac83\uacfc \uac19\uc774, \ud559\uc2b5\uc744 \uc7ac\uac1c\ud558\ub294\ub370 \ud544\uc694\ud55c \ub2e4\ub978 \ud56d\ubaa9\ub4e4\uc744 \uc0ac\uc804\uc5d0 \ucd94\uac00\ud558\uc5ec \uc800\uc7a5\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. PyTorch\uac00 \uc774\ub7ec\ud55c \uccb4\ud06c\ud3ec\uc778\ud2b8\ub97c \uc800\uc7a5\ud560 \ub54c\ub294 .tar \ud655\uc7a5\uc790\ub97c \uc0ac\uc6a9\ud558\ub294 \uac83\uc774 \uc77c\ubc18\uc801\uc778 \uaddc\uce59\uc785\ub2c8\ub2e4. \ud56d\ubaa9\ub4e4\uc744 \ubd88\ub7ec\uc62c \ub54c\uc5d0\ub294 \uba3c\uc800 \ubaa8\ub378\uacfc \uc635\ud2f0\ub9c8\uc774\uc800\ub97c \ucd08\uae30\ud654\ud55c \ud6c4, torch.load() \ub97c \uc0ac\uc6a9\ud558\uc5ec \uc0ac\uc804\uc744 \ubd88\ub7ec\uc635\ub2c8\ub2e4. \uc774\ud6c4\ub85c\ub294 \uc800\uc7a5\ub41c \ud56d\ubaa9\ub4e4\uc744 \uc0ac\uc804\uc5d0 \uc6d0\ud558\ub294\ub300\ub85c \uc0ac\uc804\uc5d0 \uc9c8\uc758\ud558\uc5ec \uc27d\uac8c \uc811\uadfc\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ucd94\ub860\uc744 \uc2e4\ud589\ud558\uae30 \uc804\uc5d0\ub294 \ubc18\ub4dc\uc2dc model.eval() \uc744 \ud638\ucd9c\ud558\uc5ec \ub4dc\ub86d\uc544\uc6c3 \ubc0f \ubc30\uce58 \uc815\uaddc\ud654\ub97c \ud3c9\uac00 \ubaa8\ub4dc\ub85c \uc124\uc815\ud558\uc5ec\uc57c \ud569\ub2c8\ub2e4. \uc774\uac83\uc744 \ud558\uc9c0 \uc54a\uc73c\uba74 \ucd94\ub860 \uacb0\uacfc\uac00 \uc77c\uad00\uc131 \uc5c6\uac8c \ucd9c\ub825\ub429\ub2c8\ub2e4. \ub9cc\uc57d \ud559\uc2b5\uc744 \uacc4\uc18d\ud558\uace0 \uc2f6\ub2e4\uba74, model.train() \uc744 \ud638\ucd9c\ud558\uc5ec \ud559\uc2b5 \ubaa8\ub4dc\ub85c \uc124\uc815\ud574\uc57c \ud569\ub2c8\ub2e4. \ub2e4\ub978 \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218\ub97c \uc0ac\uc6a9\ud558\uc5ec \ube60\ub974\uac8c \ubaa8\ub378 \uc2dc\uc791\ud558\uae30(warmstart)# \uc800\uc7a5\ud558\uae30:# torch.save(modelA.state_dict(), PATH) \ubd88\ub7ec\uc624\uae30:# modelB = TheModelBClass(*args, **kwargs) modelB.load_state_dict(torch.load(PATH, weights_only=True), strict=False) \ubd80\ubd84\uc801\uc73c\ub85c \ubaa8\ub378\uc744 \ubd88\ub7ec\uc624\uac70\ub098, \ubaa8\ub378\uc758 \uc77c\ubd80\ub97c \ubd88\ub7ec\uc624\ub294 \uac83\uc740 \uc804\uc774\ud559\uc2b5 \ub610\ub294 \uc0c8\ub85c\uc6b4 \ubcf5\uc7a1\ud55c \ubaa8\ub378\uc744 \ud559\uc2b5\ud560 \ub54c \uc77c\ubc18\uc801\uc778 \uc2dc\ub098\ub9ac\uc624\uc785\ub2c8\ub2e4. \ud559\uc2b5\ub41c \ub9e4\uac1c\ubcc0\uc218\ub97c \uc0ac\uc6a9\ud558\uba74, \uc77c\ubd80\ub9cc \uc0ac\uc6a9\ud55c\ub2e4 \ud558\ub354\ub77c\ub3c4 \ud559\uc2b5 \uacfc\uc815\uc744 \ube60\ub974\uac8c \uc2dc\uc791\ud560 \uc218 \uc788\uace0, \ucc98\uc74c\ubd80\ud130 \uc2dc\uc791\ud558\ub294 \uac83\ubcf4\ub2e4 \ud6e8\uc52c \ube60\ub974\uac8c \ubaa8\ub378\uc774 \uc218\ub834\ud558\ub3c4\ub85d \ub3c4\uc6b8 \uac83\uc785\ub2c8\ub2e4. \uba87\uba87 \ud0a4\ub97c \uc81c\uc678\ud558\uace0 state_dict \uc758 \uc77c\ubd80\ub97c \ubd88\ub7ec\uc624\uac70\ub098, \uc801\uc7ac\ud558\ub824\ub294 \ubaa8\ub378\ubcf4\ub2e4 \ub354 \ub9ce\uc740 \ud0a4\ub97c \uac16\uace0 \uc788\ub294 state_dict \ub97c \ubd88\ub7ec\uc62c \ub54c\uc5d0\ub294 load_state_dict() \ud568\uc218\uc5d0\uc11c strict \uc778\uc790\ub97c False \ub85c \uc124\uc815\ud558\uc5ec \uc77c\uce58\ud558\uc9c0 \uc54a\ub294 \ud0a4\ub4e4\uc744 \ubb34\uc2dc\ud558\ub3c4\ub85d \ud574\uc57c \ud569\ub2c8\ub2e4. \ud55c \uacc4\uce35\uc5d0\uc11c \ub2e4\ub978 \uacc4\uce35\uc73c\ub85c \ub9e4\uac1c\ubcc0\uc218\ub97c \ubd88\ub7ec\uc624\uace0 \uc2f6\uc9c0\ub9cc, \uc77c\ubd80 \ud0a4\uac00 \uc77c\uce58\ud558\uc9c0 \uc54a\uc744 \ub54c\uc5d0\ub294 \uc801\uc7ac\ud558\ub824\ub294 \ubaa8\ub378\uc758 \ud0a4\uc640 \uc77c\uce58\ud558\ub3c4\ub85d state_dict \uc758 \ub9e4\uac1c\ubcc0\uc218 \ud0a4\uc758 \uc774\ub984\uc744 \ubcc0\uacbd\ud558\uba74 \ub429\ub2c8\ub2e4. \uc7a5\uce58(device)\uac04 \ubaa8\ub378 \uc800\uc7a5\ud558\uae30 \u0026 \ubd88\ub7ec\uc624\uae30# GPU\uc5d0\uc11c \uc800\uc7a5\ud558\uace0 CPU\uc5d0\uc11c \ubd88\ub7ec\uc624\uae30# \uc800\uc7a5\ud558\uae30: torch.save(model.state_dict(), PATH) \ubd88\ub7ec\uc624\uae30: device = torch.device(\u0027cpu\u0027) model = TheModelClass(*args, **kwargs) model.load_state_dict(torch.load(PATH, map_location=device, weights_only=True)) GPU\uc5d0\uc11c \ud559\uc2b5\ud55c \ubaa8\ub378\uc744 CPU\uc5d0\uc11c \ubd88\ub7ec\uc62c \ub54c\ub294 torch.load() \ud568\uc218\uc758 map_location \uc778\uc790\uc5d0 torch.device(\u0027cpu\u0027) \uc744 \uc804\ub2ec\ud569\ub2c8\ub2e4. \uc774 \uacbd\uc6b0\uc5d0\ub294 Tensor\uc5d0 \uc800\uc7a5\ub41c \ub0b4\uc6a9\ub4e4\uc740 map_location \uc778\uc790\ub97c \uc0ac\uc6a9\ud558\uc5ec CPU \uc7a5\uce58\uc5d0 \ub3d9\uc801\uc73c\ub85c \uc7ac\ubc30\uce58\ub429\ub2c8\ub2e4. GPU\uc5d0\uc11c \uc800\uc7a5\ud558\uace0 GPU\uc5d0\uc11c \ubd88\ub7ec\uc624\uae30# \uc800\uc7a5\ud558\uae30: torch.save(model.state_dict(), PATH) \ubd88\ub7ec\uc624\uae30: device = torch.device(\"cuda\") model = TheModelClass(*args, **kwargs) model.load_state_dict(torch.load(PATH, weights_only=True)) model.to(device) # \ubaa8\ub378\uc5d0\uc11c \uc0ac\uc6a9\ud558\ub294 input Tensor\ub4e4\uc740 input = input.to(device) \uc744 \ud638\ucd9c\ud574\uc57c \ud569\ub2c8\ub2e4. GPU\uc5d0\uc11c \ud559\uc2b5\ud55c \ubaa8\ub378\uc744 GPU\uc5d0\uc11c \ubd88\ub7ec\uc62c \ub54c\uc5d0\ub294, \ucd08\uae30\ud654\ub41c model \uc5d0 model.to(torch.device(\u0027cuda\u0027)) \uc744 \ud638\ucd9c\ud558\uc5ec CUDA \ucd5c\uc801\ud654\ub41c \ubaa8\ub378\ub85c \ubcc0\ud658\ud574\uc57c \ud569\ub2c8\ub2e4. \ub610\ud55c, \ubaa8\ub378\uc5d0 \ub370\uc774\ud130\ub97c \uc81c\uacf5\ud558\ub294 \ubaa8\ub4e0 \uc785\ub825\uc5d0 .to(torch.device(\u0027cuda\u0027)) \ud568\uc218\ub97c \ud638\ucd9c\ud574\uc57c \ud569\ub2c8\ub2e4. my_tensor.to(device) \ub97c \ud638\ucd9c\ud558\uba74 GPU\uc5d0 my_tensor \uc758 \ubcf5\uc0ac\ubcf8\uc744 \ubc18\ud658\ud558\uae30 \ub54c\ubb38\uc5d0, Tensor\ub97c \uc9c1\uc811 \ub36e\uc5b4\uc368\uc57c \ud569\ub2c8\ub2e4: my_tensor = my_tensor.to(torch.device(\u0027cuda\u0027)) . CPU\uc5d0\uc11c \uc800\uc7a5\ud558\uace0 GPU\uc5d0\uc11c \ubd88\ub7ec\uc624\uae30# \uc800\uc7a5\ud558\uae30: torch.save(model.state_dict(), PATH) \ubd88\ub7ec\uc624\uae30: device = torch.device(\"cuda\") model = TheModelClass(*args, **kwargs) model.load_state_dict(torch.load(PATH, weights_only=True, map_location=\"cuda:0\")) # \uc0ac\uc6a9\ud560 GPU \uc7a5\uce58 \ubc88\ud638\ub97c \uc120\ud0dd\ud569\ub2c8\ub2e4. model.to(device) # \ubaa8\ub378\uc5d0\uc11c \uc0ac\uc6a9\ud558\ub294 input Tensor\ub4e4\uc740 input = input.to(device) \uc744 \ud638\ucd9c\ud574\uc57c \ud569\ub2c8\ub2e4. CPU\uc5d0\uc11c \ud559\uc2b5\ud55c \ubaa8\ub378\uc744 GPU\uc5d0\uc11c \ubd88\ub7ec\uc62c \ub54c\ub294 torch.load() \ud568\uc218\uc758 map_location \uc778\uc790\uc5d0 cuda:device_id \uc744 \uc124\uc815\ud569\ub2c8\ub2e4. \uc774\ub807\uac8c \ud558\uba74 \ubaa8\ub378\uc774 \ud574\ub2f9 GPU \uc7a5\uce58\uc5d0 \ubd88\ub7ec\uc640\uc9d1\ub2c8\ub2e4. \ub2e4\uc74c\uc73c\ub85c model.to(torch.device(\u0027cuda\u0027)) \uc744 \ud638\ucd9c\ud558\uc5ec \ubaa8\ub378\uc758 \ub9e4\uac1c\ubcc0\uc218 Tensor\ub4e4\uc744 CUDA Tensor\ub4e4\ub85c \ubcc0\ud658\ud574\uc57c \ud569\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9\uc73c\ub85c \ubaa8\ub4e0 \ubaa8\ub378 \uc785\ub825\uc5d0 .to(torch.device(\u0027cuda\u0027)) \uc744 \uc0ac\uc6a9\ud558\uc5ec CUDA \ucd5c\uc801\ud654\ub41c \ubaa8\ub378\uc744 \uc704\ud55c \ub370\uc774\ud130\ub85c \ub9cc\ub4e4\uc5b4\uc57c \ud569\ub2c8\ub2e4. my_tensor.to(device) \ub97c \ud638\ucd9c\ud558\uba74 GPU\uc5d0 my_tensor \uc758 \ubcf5\uc0ac\ubcf8\uc744 \ubc18\ud658\ud569\ub2c8\ub2e4. \uc774 \ub3d9\uc791\uc740 my_tensor \ub97c \ub36e\uc5b4\uc4f0\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0, Tensor\ub97c \uc9c1\uc811 \ub36e\uc5b4\uc368\uc57c \ud569\ub2c8\ub2e4: my_tensor = my_tensor.to(torch.device(\u0027cuda\u0027)) . torch.nn.DataParallel \ubaa8\ub378 \uc800\uc7a5\ud558\uae30# \uc800\uc7a5\ud558\uae30: torch.save(model.module.state_dict(), PATH) \ubd88\ub7ec\uc624\uae30: # \uc0ac\uc6a9\ud560 \uc7a5\uce58\uc5d0 \ubd88\ub7ec\uc635\ub2c8\ub2e4. torch.nn.DataParallel \uc740 \ubcd1\ub82c GPU \ud65c\uc6a9\uc744 \uac00\ub2a5\ud558\uac8c \ud558\ub294 \ubaa8\ub378 \ub798\ud37c(wrapper)\uc785\ub2c8\ub2e4. DataParallel \ubaa8\ub378\uc744 \ubc94\uc6a9\uc801\uc73c\ub85c \uc800\uc7a5\ud558\ub824\uba74 model.module.state_dict() \uc744 \uc0ac\uc6a9\ud558\uba74 \ub429\ub2c8\ub2e4. \uc774\ub807\uac8c \ud558\uba74 \uc6d0\ud558\ub294 \ubaa8\ub4e0 \uc7a5\uce58\uc5d0 \uc6d0\ud558\ub294 \ubc29\uc2dd\uc73c\ub85c \uc720\uc5f0\ud558\uac8c \ubaa8\ub378\uc744 \ubd88\ub7ec\uc62c \uc218 \uc788\uc2b5\ub2c8\ub2e4. Total running time of the script: (0 minutes 0.000 seconds) Download Jupyter notebook: saving_loading_models.ipynb Download Python source code: saving_loading_models.py Download zipped: saving_loading_models.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/beginner/saving_loading_models.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>